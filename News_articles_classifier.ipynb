{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a text classifier for classifying news articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will\n",
    "1. Scrape data from a website called Inshorts\n",
    "2. Scrape data for 3 news categories : sports, world, technology\n",
    "3. Scrape news headline and news article\n",
    "3. Build a text classifier to classify the news articles\n",
    "\n",
    "Disclosure : web scraping code is referred from https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. requests to get the access to HTML content from the landing page\n",
    "2. BeautifulSoup to parse the data and extract headline and articls for all the 3 categories (sports, technology and world affairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urls to the news articles\n",
    "seed_urls = ['https://www.inshorts.com/en/read/sports',\n",
    "            'https://www.inshorts.com/en/read/technology',\n",
    "            'https://www.inshorts.com/en/read/world']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for scraping the data from given urls\n",
    "def build_datasets(seed_urls):\n",
    "    \n",
    "    news_data = []\n",
    "    \n",
    "    for url in seed_urls:\n",
    "        news_category = url.split('/')[-1]\n",
    "        \n",
    "        data = requests.get(url)\n",
    "        soup = BeautifulSoup(data.content,'html.parser')\n",
    "        \n",
    "        news_articles = [{'news_headline': headline.find('span', \n",
    "                                                         attrs={\"itemprop\": \"headline\"}).string,\n",
    "                          'news_article': article.find('div', \n",
    "                                                       attrs={\"itemprop\": \"articleBody\"}).string,\n",
    "                          'news_category': news_category}\n",
    "                         \n",
    "                            for headline, article in \n",
    "                             zip(soup.find_all('div', \n",
    "                                               class_=[\"news-card-title news-right-box\"]),\n",
    "                                 soup.find_all('div', \n",
    "                                               class_=[\"news-card-content news-right-box\"]))\n",
    "                        ]\n",
    "        news_data.extend(news_articles)\n",
    "        \n",
    "    df =  pd.DataFrame(news_data)\n",
    "    df = df[['news_headline', 'news_article', 'news_category']]\n",
    "  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = build_datasets(seed_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data has 73 news articles from 3 categories\n",
    "news_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sports        25\n",
       "technology    24\n",
       "world         24\n",
       "Name: news_category, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Distribution of news articles over 3 categories\n",
    "news_df.news_category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining news article and news headline into a new column 'news'\n",
    "news_df['news'] = news_df['news_headline']+news_df['news_article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting train and test data into 75% and 25% respectively\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = news_df[['news']]\n",
    "y = news_df['news_category']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify = y, test_size =0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sports        18\n",
       "world         18\n",
       "technology    18\n",
       "Name: news_category, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#each category has equal number of news article. \n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building pipeline to first process the text data using TFIDF and then classifying using RidgeClassifier\n",
    "#### 1. max_df and min_df parameters are tuned for TFIDF.\n",
    "#### 2. alpha is tuned for ridge classifier.\n",
    "#### 3. StratifiedKFold is used for preserving the percentage of samples for each class.\n",
    "#### 4. ngram_range for TFIDF is set to (1,2), using unigrams and bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      sports       0.86      0.86      0.86         7\n",
      "  technology       1.00      0.67      0.80         6\n",
      "       world       0.75      1.00      0.86         6\n",
      "\n",
      "   micro avg       0.84      0.84      0.84        19\n",
      "   macro avg       0.87      0.84      0.84        19\n",
      "weighted avg       0.87      0.84      0.84        19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramya.gowda/miniconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "pipeline = Pipeline([('tfidf',TfidfVectorizer(ngram_range=(1,2))),\n",
    "                     ('clf',RidgeClassifier())])\n",
    "\n",
    "param_grid = ({'tfidf__max_df':[.6,.7,.8,.9],\n",
    "              'tfidf__min_df':[0,.1,.2],\n",
    "              'clf__alpha': [.001,.01,.1,1,10,100,1000]})\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, cv=5, param_grid=param_grid)\n",
    "\n",
    "grid_search.fit(X_train.news, y_train)\n",
    "y_pred = grid_search.predict(X_test.news)\n",
    "\n",
    "print(classification_report(y_pred=y_pred, y_true = y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.001, 'tfidf__max_df': 0.7, 'tfidf__min_df': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best parameters are given as :\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
